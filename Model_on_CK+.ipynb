{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aae6dc2-3bfa-4aad-b67b-0d4989d51e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4174c106-5497-4930-b423-687f6bc98c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE:  cpu\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('DEVICE: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7539684c-587c-4dc7-9daf-c94a597a8abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.1\n",
    "FEATURE_IDX = 1\n",
    "RANDOM_SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb40e8c7-3cc0-4c77-86f2-3c24da222267",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f1cf6d-29fe-48b7-8879-5f2afc268cca",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/CK+ Dataset/train_data/_classes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 67\u001b[0m\n\u001b[0;32m     63\u001b[0m             image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(Image\u001b[38;5;241m.\u001b[39mfromarray(image))  \u001b[38;5;66;03m# Convert to PIL before transforms\u001b[39;00m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m image, torch\u001b[38;5;241m.\u001b[39mtensor(label, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m---> 67\u001b[0m Train_Dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCKPlusDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrain_Dataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrain_labels_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_transforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m Test_Dataset \u001b[38;5;241m=\u001b[39m CKPlusDataset(img_dir\u001b[38;5;241m=\u001b[39mTest_Dataset_path, label_dir\u001b[38;5;241m=\u001b[39mTest_labels_dataset, transform\u001b[38;5;241m=\u001b[39mtest_transforms)\n\u001b[0;32m     69\u001b[0m Valid_Dataset \u001b[38;5;241m=\u001b[39m CKPlusDataset(img_dir\u001b[38;5;241m=\u001b[39mValid_Dataset_path, label_dir\u001b[38;5;241m=\u001b[39mValid_labels_dataset, transform\u001b[38;5;241m=\u001b[39mtest_transforms)\n",
      "Cell \u001b[1;32mIn[5], line 39\u001b[0m, in \u001b[0;36mCKPlusDataset.__init__\u001b[1;34m(self, img_dir, label_dir, transform)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Read CSV file\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Ensure column names are correct\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manger\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontempt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisgust\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhappy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msadness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurprise\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CK+ Dataset/train_data/_classes.csv'"
     ]
    }
   ],
   "source": [
    "# TRANSFORMS\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "Train_Dataset_path = '/content/drive/MyDrive/CK+ Dataset/train_data/train'\n",
    "Train_labels_dataset = '/content/drive/MyDrive/CK+ Dataset/train_data/_classes.csv'\n",
    "Test_Dataset_path = '/content/drive/MyDrive/CK+ Dataset/test_data/test'\n",
    "Test_labels_dataset = '/content/drive/MyDrive/CK+ Dataset/test_data/_classes.csv'\n",
    "Valid_Dataset_path = '/content/drive/MyDrive/CK+ Dataset/valid_data/valid'\n",
    "Valid_labels_dataset = '/content/drive/MyDrive/CK+ Dataset/valid_data/_classes.csv'\n",
    "\n",
    "EMOTION_CLASSES = {\n",
    "    0: \"anger\",\n",
    "    1: \"contempt\",\n",
    "    2: \"disgust\",\n",
    "    3: \"fear\",\n",
    "    4: \"happiness\",\n",
    "    5: \"sadness\",\n",
    "    6: \"surprise\"\n",
    "}\n",
    "\n",
    "# Custom PyTorch dataset\n",
    "class CKPlusDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Read CSV file\n",
    "        self.data = pd.read_csv(label_dir)\n",
    "\n",
    "        # Ensure column names are correct\n",
    "        self.data.columns = [\"filename\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx, 0]  # Image filename\n",
    "        label = self.data.iloc[idx, 1:].values.astype(int)  # Multi-class labels (one-hot)\n",
    "        label = np.argmax(label)  # Convert one-hot to class index\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "\n",
    "        # Check if image exists\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        image = cv2.resize(image, (128, 128))  # Resize to (128,128)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(Image.fromarray(image))  # Convert to PIL before transforms\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "Train_Dataset = CKPlusDataset(img_dir=Train_Dataset_path, label_dir=Train_labels_dataset, transform=train_transforms)\n",
    "Test_Dataset = CKPlusDataset(img_dir=Test_Dataset_path, label_dir=Test_labels_dataset, transform=test_transforms)\n",
    "Valid_Dataset = CKPlusDataset(img_dir=Valid_Dataset_path, label_dir=Valid_labels_dataset, transform=test_transforms)\n",
    "\n",
    "print(f\"Train dataset size: {len(Train_Dataset)}\")\n",
    "print(f\"Test dataset size: {len(Test_Dataset)}\")\n",
    "print(f\"Valid dataset size: {len(Valid_Dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(Train_Dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(Test_Dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(Valid_Dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d48e3f8-6554-4364-8a7a-312772b517b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_loader\u001b[49m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimages\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# (batch_size, 3, 128, 128)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(f\"Batch shape: {images.shape}\")  # (batch_size, 3, 128, 128)\n",
    "    print(f\"Labels: {labels}\")\n",
    "    break\n",
    "\n",
    "EXAMPLE_IMG = images[0]\n",
    "EXAMPLE_LABEL = labels[0]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "ax.imshow(EXAMPLE_IMG.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6a21f8-3925-4f8a-8ee7-74148ce0f4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2687f9284b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d459ac03-ce2c-4f2d-9f08-4755152bc7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.size = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.size)\n",
    "\n",
    "class Trim(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :128, :128]\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, stride=2, kernel_size=3, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            #\n",
    "            nn.Conv2d(32, 64, stride=2, kernel_size=3, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            #\n",
    "            nn.Conv2d(64, 64, stride=2, kernel_size=3, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            #\n",
    "            nn.Conv2d(64, 64, stride=2, kernel_size=3, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            #\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.z_mean = torch.nn.Linear(4096, 200)\n",
    "        self.z_log_var = torch.nn.Linear(4096, 200)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            torch.nn.Linear(200, 4096),\n",
    "            Reshape(-1, 64, 8, 8),\n",
    "            #\n",
    "            nn.ConvTranspose2d(64, 64, stride=2, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            #\n",
    "            nn.ConvTranspose2d(64, 64, stride=2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            #\n",
    "            nn.ConvTranspose2d(64, 32, stride=2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            #\n",
    "            nn.ConvTranspose2d(32, 3, stride=2, kernel_size=3, padding=1),\n",
    "            Trim(),  # 3x129x129 -> 3x128x128\n",
    "            nn.Sigmoid(),\n",
    "            Reshape(-1, 3, 128, 128)\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, z_mean, z_log_var):\n",
    "        eps = torch.randn(z_mean.size(0), z_mean.size(1)).to(z_mean.device)\n",
    "        z = z_mean + torch.exp(z_log_var / 2) * eps\n",
    "        return z\n",
    "\n",
    "    def encoding_fn(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean = self.z_mean(x)\n",
    "        z_log_var = self.z_log_var(x)\n",
    "        encoded = self.reparameterize(z_mean, z_log_var)\n",
    "        return encoded\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
    "        encoded = self.reparameterize(z_mean, z_log_var)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, z_mean, z_log_var, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d770a161-1f15-44e6-890c-e29ea3a3abfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (3): Dropout2d(p=0.25, inplace=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (7): Dropout2d(p=0.25, inplace=False)\n",
       "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (11): Dropout2d(p=0.25, inplace=False)\n",
       "    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (15): Dropout2d(p=0.25, inplace=False)\n",
       "    (16): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (z_mean): Linear(in_features=4096, out_features=200, bias=True)\n",
       "  (z_log_var): Linear(in_features=4096, out_features=200, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=4096, bias=True)\n",
       "    (1): Reshape()\n",
       "    (2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (5): Dropout2d(p=0.25, inplace=False)\n",
       "    (6): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (9): Dropout2d(p=0.25, inplace=False)\n",
       "    (10): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (13): Dropout2d(p=0.25, inplace=False)\n",
       "    (14): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (15): Trim()\n",
       "    (16): Sigmoid()\n",
       "    (17): Reshape()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1053bb-6be1-4c2f-9fe4-1bd5b68294f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_face(feature_idx, image_dim, data_loader, device=None, encoding_fn=None):\n",
    "    avg_img_with_feat = torch.zeros(image_dim, dtype=torch.float32)\n",
    "    avg_img_without_feat = torch.zeros(image_dim, dtype=torch.float32)\n",
    "\n",
    "    num_img_with_feat = 0\n",
    "    num_images_without_feat = 0\n",
    "\n",
    "    for images, labels in data_loader:\n",
    "        idx_img_with_feat = labels == feature_idx\n",
    "\n",
    "        if encoding_fn is None:\n",
    "            embeddings = images\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                if device is not None:\n",
    "                    images = images.to(device)\n",
    "                embeddings = encoding_fn(images).to('cpu')\n",
    "\n",
    "        avg_img_with_feat += torch.sum(embeddings[idx_img_with_feat], axis=0)\n",
    "        avg_img_without_feat += torch.sum(embeddings[~idx_img_with_feat], axis=0)\n",
    "        num_img_with_feat += idx_img_with_feat.sum().item()\n",
    "        num_images_without_feat += (~idx_img_with_feat).sum().item()\n",
    "\n",
    "    avg_img_with_feat /= num_img_with_feat\n",
    "    avg_img_without_feat /= num_images_without_feat\n",
    "\n",
    "    return avg_img_with_feat, avg_img_without_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ad09d39-5407-4a1d-ba49-824c2a7b9e67",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m avg_face_with_feature, avg_face_with_out_feature \u001b[38;5;241m=\u001b[39m compute_avg_face(feature_idx\u001b[38;5;241m=\u001b[39mFEATURE_IDX,\n\u001b[0;32m      2\u001b[0m                                                                     image_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m----> 3\u001b[0m                                                                     data_loader\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_loader\u001b[49m,\n\u001b[0;32m      4\u001b[0m                                                                     device\u001b[38;5;241m=\u001b[39mDEVICE,\n\u001b[0;32m      5\u001b[0m                                                                     encoding_fn\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencoding_fn)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "avg_face_with_feature, avg_face_with_out_feature = compute_avg_face(feature_idx=FEATURE_IDX,\n",
    "                                                                    image_dim=200,\n",
    "                                                                    data_loader=train_loader,\n",
    "                                                                    device=DEVICE,\n",
    "                                                                    encoding_fn=model.encoding_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d283a216-acdc-4f41-a47a-c1fe1a9c2d29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg_face_with_feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m diff \u001b[38;5;241m=\u001b[39m \u001b[43mavg_face_with_feature\u001b[49m \u001b[38;5;241m-\u001b[39m avg_face_with_out_feature\n\u001b[0;32m      2\u001b[0m example_img \u001b[38;5;241m=\u001b[39m EXAMPLE_IMG\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'avg_face_with_feature' is not defined"
     ]
    }
   ],
   "source": [
    "diff = avg_face_with_feature - avg_face_with_out_feature\n",
    "example_img = EXAMPLE_IMG.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model.encoding_fn(example_img).squeeze(0).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e5f5d4a-ba3d-4898-a1f9-26ee2543c235",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m         axes[\u001b[38;5;241m1\u001b[39m][i]\u001b[38;5;241m.\u001b[39maxison \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     30\u001b[0m         axes[\u001b[38;5;241m0\u001b[39m][i]\u001b[38;5;241m.\u001b[39maxison \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m plot_modified_faces(original\u001b[38;5;241m=\u001b[39m\u001b[43membeddings\u001b[49m, diff\u001b[38;5;241m=\u001b[39mdiff, decoding_fn\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdecoder, device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[0;32m     33\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m     34\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_modified_faces(original, diff, diff_coefficients=(0., 0.5, 1., 1.5, 2., 2.5, 3.), decoding_fn=None, device=None, figsize=(8, 2.5)):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=len(diff_coefficients), sharex=True, sharey=True, figsize=figsize)\n",
    "\n",
    "    for i, alpha in enumerate(diff_coefficients):\n",
    "        more = original + alpha * diff\n",
    "        less = original - alpha * diff\n",
    "\n",
    "        if decoding_fn is not None:\n",
    "            with torch.no_grad():\n",
    "                if device is not None:\n",
    "                    more = more.to(device).unsqueeze(0)\n",
    "                    less = less.to(device).unsqueeze(0)\n",
    "\n",
    "                more = decoding_fn(more).to('cpu').squeeze(0)\n",
    "                less = decoding_fn(less).to('cpu').squeeze(0)\n",
    "\n",
    "        \n",
    "        more = transforms.CenterCrop(128)(more)\n",
    "        less = transforms.CenterCrop(128)(less)\n",
    "\n",
    "        if not alpha:\n",
    "            s = 'original'\n",
    "        else:\n",
    "            s = f'$\\\\alpha={alpha}$'\n",
    "\n",
    "        axes[0][i].set_title(s)\n",
    "        axes[0][i].imshow(more.permute(1, 2, 0))\n",
    "        axes[1][i].imshow(less.permute(1, 2, 0))\n",
    "        axes[1][i].axison = False\n",
    "        axes[0][i].axison = False\n",
    "\n",
    "plot_modified_faces(original=embeddings, diff=diff, decoding_fn=model.decoder, device=DEVICE)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3e3dd-6af7-45aa-804f-bec85102b149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
